{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 103,
>>>>>>> 946b4e2 (Updated)
   "metadata": {},
   "outputs": [],
   "source": [
    "# where xgboost works better\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xgboost as xg \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error as MSE \n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 107,
>>>>>>> 946b4e2 (Updated)
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.multivariate_normal([0, 0], [[1, 0.9], [0.9, 1]], 10000)\n",
<<<<<<< HEAD
    "y = X[:,1]/np.sqrt((X[:,0])**2+(X[:,1])**2) + np.random.normal(0, 0.1, size=len(X))\n",
=======
    "y= 2*X[:,1]/np.sqrt((X[:,0])**2+(X[:,1])**2) + np.random.normal(0, 0.1, size=len(X))\n",
>>>>>>> 946b4e2 (Updated)
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                      test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 108,
>>>>>>> 946b4e2 (Updated)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Test MSE: 0.015252620918326968\n",
      "R sqr: 0.9699158076591037\n"
=======
      "Test MSE: 0.017146930747777466\n",
      "R sqr: 0.9912460708087135\n"
>>>>>>> 946b4e2 (Updated)
     ]
    }
   ],
   "source": [
    "  \n",
    "# Instantiation \n",
    "xgb_r = xg.XGBRegressor(objective ='reg:squarederror', max_depth=20, subsample=0.7,learning_rate = 0.5, alpha = 0,\n",
    "                  n_estimators = 10, seed = 123) \n",
    "  \n",
    "# Fitting the model \n",
    "xgb_r.fit(train_X, train_y) \n",
    "  \n",
    "# Predict the model \n",
    "pred = xgb_r.predict(test_X) \n",
    "  \n",
    "# MSE Computation \n",
    "mse = MSE(test_y, pred)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "r2= r2_score(test_y, pred)\n",
    "print(\"R sqr:\", r2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 109,
>>>>>>> 946b4e2 (Updated)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JYOTISHKA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:255: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Test MSE: 0.20691945242368198\n",
      "R sqr: 0.59187311878267\n"
=======
      "Test MSE: 0.22478098261526733\n",
      "R sqr: 0.8852437888560967\n"
>>>>>>> 946b4e2 (Updated)
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# Fit the kernel regression model\n",
    "alpha = 0  # Regularization parameter\n",
<<<<<<< HEAD
    "gamma = 0.0001  # Kernel coefficient / Bandwidth\n",
=======
    "gamma = 0.003  # Kernel coefficient\n",
>>>>>>> 946b4e2 (Updated)
    "kernel_reg = KernelRidge(alpha=alpha, kernel='rbf', gamma=gamma)\n",
    "kernel_reg.fit(train_X, train_y)\n",
    "\n",
    "# Predict on the training and testing data\n",
    "#y_train_pred = kernel_reg.predict(X_train)\n",
    "y_test_pred = kernel_reg.predict(test_X) \n",
    "\n",
    "# test comment\n",
    "\n",
    "# Calculate the mean squared error\n",
    "#mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse = MSE(test_y, y_test_pred)\n",
    "\n",
    "#print(\"Train MSE:\", mse_train)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "r2= r2_score(test_y, y_test_pred)\n",
    "print(\"R sqr:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 110,
>>>>>>> 946b4e2 (Updated)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Test MSE: 0.019275493461185615\n",
      "R sqr: 0.9619811142060689\n"
=======
      "Test MSE: 0.023356770147759286\n",
      "R sqr: 0.9880757953118147\n"
>>>>>>> 946b4e2 (Updated)
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_regressor = GradientBoostingRegressor(loss=\"squared_error\",n_estimators=100, learning_rate=0.5, max_depth=20, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_regressor.fit(train_X, train_y)\n",
    "pred = gb_regressor.predict(test_X)\n",
    "\n",
    "# MSE Computation \n",
    "mse = MSE(test_y, pred)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "r2= r2_score(test_y, pred)\n",
    "print(\"R sqr:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
